---
---
# 빅데이터 공부

## 도커

- 리눅스 컨테이너 기반 vm
- 게스트 os 없음
- 환경 격리
- 때문에 컨테이너 하나에 하나의 프로세스가 관례
- dockerfile로 이미지 관리할 수 있어 버전 관리에 유리

## 컨테이너 오케스트레이션

- (도커 스웜 등등 최근 쿠버네티스가 많이 쓰임)

### 쿠버네티스

- 배포, 스케줄링, 스케일링, 클러스터링, 모너터링, 네트워크, 권한 관리, 네임스페이스, 라벨 등등 제공

- 오브젝트가 있고 pod, volumn, namespace, service
- pod은 컨테이너, 볼륨으로 구성할 수 있음
- node는 쿠블릿, 쿠브프록시, pod들을 갖고 있는 단위이다.
- 쿠브 api-server(마스터)가 노드들을 관리하고 사용자는 쿠브 컨트롤러를 통하여 api-server에 명령을 내린다.

- 쿠버네티스의 명령체계는 current state, desired state 즉, 스테이트 기술로 이루어 진다.

## 하둡

- High Availablity Distributed Object-Oriented Platform
- 빅데이터를 저장하고 처리할 수 있는 자바 기반 플랫폼

## HDFS

- Hadoop Distributed File System
- **block** 단위로 관리하는 분산 파일 시스템
- 큰 파일을 저장할 경우 블록으로 나누어 여러 서버에 나누어 저장 가능
- 블록은 대게 128mb정도 임
- 블록은 대게 3개로 복제되어 저장(고가용성)

- **네임 노드** 는 데이터 노드 모니터링, 블록 관리(장애 발생 시 블록 복제 등등), 클라이언트 요청 처리
  + 블록 변경 시 **editslog** 와 **fsimage** 로 메타데이터 저장
  + editslog는 용량이 커서 주기적으로 fsimage로 저장
  + fsimage로 저장할 경우 시간이 오래 걸리므로
  + secondary 네임 노드에서 이 작업, **체크 포인트** 작업을 진행함
- **데이터 노드**가 실제 저장

## 맵-리듀스

- 분산 배치 처리를 하기 위한 프래임워크

- 클라이언트에서 **잡** 을 받아 관리하는 **잡 트래커(마스터)** 가 **태스크 트래커** 에 잡을 실행 시킴
- 태스크 트레커
  + 맵 태스크 / 리듀스 태스크가 진행됨

- 맵 태스크, 리듀스 태스크
  + Map Side
    * input split(row data) : split 하나 당 하나의 맵 태스크
    * RecordReader : input data를 key value 형태로 만들고 맵퍼에 전달
    * 맵퍼은 레코드를 새로운 key value로 가공
    * 파티셔너(shuffling 과정 시작)
      - partitioning(기본 key hash 기준, 메모리, pre-sort도 진행됨) + spill(to disk, 버퍼가 일정 크기 도달) + 1file merge(출력 파일 - partition 별로 정렬됨)
  + (컴바이너)
    * 로컬 리듀스
  + Reduce Side
    * copy phase
      - 맵 태스크(가 완료되면)의 출력 데이터를 네트워크 복사
      - 크면 disk, 작으면 memory, 필요하면 combiner
    * merge phase
      - 키 기준으로 병합
    * RecordWriter
      - HDFS에 저장

# Hive

- SQL과 유사한 HQL를 사용할 수 있는 프레임워크
- MapReduce 기반 DW 프레임워크
- 구성
  + UI
  + Driver(쿼리 입력받고 처리)
  + Complier(메타스토어, 실행계획 생성)
  + MetaStore(스키마 등 정보 관리)
  + ExcuteEngine(job 실행)
- 테이블/파티션/버킷
  + 테이블 / 파티션 : 디렉토리 나누기
  + 버켓팅 : 파일 나누기
- join 종류
  + (shuffle) join
  + map(side) join(작은 25mb)
  + skew join(데이터 편중된)
  + Sort Merge Bucket join(**bucket column** 기반 맵리듀스 진행)
- 정렬 관련
  + sort by - 리듀서 별 정렬, select 시 순서 보장 안됨
  + distributed by (컬럼 값 일치 동일 리듀서(파일), group by와 유사 - select 시 순서 보장 안됨)
  + cluster by(d + s 같이)
  + order by(한 리듀서에서) - limit 권장

# HBASE

- HDFS 기반 분산 컬럼 DB - NoSql
- CP 만족(Consistancy, Availablity, Partition totorance)
- 테이블, key, Value(도큐먼트 구조)
- HBase Key는 row key, column family, column qualifer, timestamp 그리고 type
- RowKey는 오름차순 정렬

- **변경**
  + timestamp를 최신으로 해야 add하는 형식으로 추가

- **삭제**
  + type에 삭제 플래그를 설정하는 방식
  + 이는 읽기 성능 저하가 읽어날 수 있음
  + minor/major compaction을 통해 크기를 줄임
    * minor compaction
      - 몇개 작은 hfile을 병합하여 큰 hfile로 생성
    * major compaction
      - region 단위 compaction

- 데이터 기록 과정
  + **HMaster** 에 hbase catelog에 **Region Server** (Data node) 찾기
  + region server에서
    * **WAL** (Write Ahead Log)에 로그로 기록(바로 ack보냄)
    * **memstore** 에 데이터 업데이트
    * 용량 다차면 **hfile** 로 flush (hdfs에 분산 저장)

- 읽기
  + 자주 읽는 hfile은 **block cache** 로 캐싱

- 구조
  + HMaster는 Region Server 관리(주키퍼를 통해)
  + Region Server에는 Region 들이 있음
  + Region이 커지면 Region Server는 로컬에서 Region1, Region2 이런 식으로 Region을 나눔
  + 이후 Region 을 다른 서버로 이동시킴(로드 밸런싱)

# HUE

- Hadoop User Experience

# 카프카

- pub-sub 모델의 분산 메시지큐, pulling 방식
- **producer** : 메시지 생산자
- consumer : 메시지 처리자
- consumer group : 하나의 토픽 책임

- **토픽** - **파티션** (라운드로빈) - offset
  + 메시지 구분 토픽
  + 토픽은 하나 이상의 파티션으로 구성
  + 파티션이 2개 이상일 경우 라운드 로빈으로 메시지가 push됨
  + 컨슈머는 하나 이상의 파티션을 담당하게 되며 처리한 메시지까지를 offset으로 기록함
  + 파티션 < 컨슈머 일 경우 노는 컨슈머가 있게 됨

- 카프카 서버는 **브로커** 라고 하고 주키퍼로 카프카 서버를 관리한다.

- 리플리카 설정을 할 수 있는데. 리드 브로커가 장애나 날 시 팔로어 브로커를 리드 브로커로 하여 고가용성을 제공
- ack 옵션 1(default) 리더만 ack 확인 -1(all) 모든 팔로어 ack시 ack응답

- 참고 [[https://devtimes.com/bigdata/2019/01/18/what-is-kafka/]]

## Error: NOT_LEADER_FOR_PARTITION

- 하나의 브로커는 하나 이상의 토픽을 처리하는데, 각 브로커는 리더 토픽을 갖는다.   
  프로듀서 클라이언트나 컨슈머 클라이언트가 리더 토픽이 아닌 **팔로우** 토픽을 요청하면   
  요청을 reject하는 경우가 있나보다.

- 아래 명령을 통하여 topic별 브로커를 확인할 수 있다.

```bash
./kafka-topics.sh --zookeeper localhost:2181 --topic your_topic --describe

Topic: your_topic   PartitionCount:3    ReplicationFactor:1 Configs:retention.ms=14400000
Topic: your_topic   Partition: 0    Leader: 2   Replicas: 2 Isr: 2
Topic: your_topic   Partition: 1    Leader: 0   Replicas: 0 Isr: 0
Topic: your_topic   Partition: 2    Leader: 1   Replicas: 1 Isr: 1
```

- 참고 [[https://stackoverflow.com/questions/47767169/kafka-this-server-is-not-the-leader-for-that-topic-partition]]

# Spark

- 분산 쿼리 / 처리 엔진
- 고속 범용 분산 컴퓨팅 플랫폼
- **컬랙션 기반 API 제공** - 클러스터를 다루지 않아도 됨
- **일괄처리 기능(map reduce 같이)** , **실시간 데이터 처리 기능(스트리밍)** , **SQL** , **머신러닝 알고리즘** 등등
- 빠른 이유 메모리 캐싱 특히 **반복 알고리즘**에 적합

- **RDD** 는 lazy excution 제공
- RDD는 Transformations 과정, Action 과정이 있어

- transformations 데이터를 어떻게 변환 시키는지만 기술
- action : transformation 계산
- transformations이 있어 스케줄러에서 최적화를 할 수 있게 함

- 트랜젝션 지원 안해 OATP에 적합하지 않음
